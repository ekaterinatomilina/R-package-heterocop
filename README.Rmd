---
title: "Heterocop"
author: "Ekaterina Tomilina"
date: "`r Sys.Date()`"
output: pdf_document
bibliography: biblio.bib
vignette: >
  %\VignetteIndexEntry{Vignette Title}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

This package enables the user to simulate data which multivariate cumulative distribution function (CDF) can be associated to a Gaussian copula. It can also estimate the correlation matrix of the copula.

## Context

When working with $d$ heterogeneous vectors $X_1, ..., X_d$, it can be complicated to infer a correlation network as well-known statistical methods do not work in case of mixed data. Indeed, most classical network inference methods such as glasso or Gaussian graphical models rely on the assumption that the data follow a Gaussian distribution. Recently, the Non-paranormal distribution was introduced for network inference for continuous, non-Gaussian data (@liu). It consists in a transformation of the cumulative distribution functions via a Gaussian copula and provides results in the continuous case. The aim of my PhD thesis, which is currently in process, is to extend this method to discrete and mixed variables.

## The Model

Let $X_1, ..., X_d$ be $d$ $n-$dimensional vectors of any type (continuous, mixed, discrete...). Let $F_1, ..., F_d$ denote their marginal CDFs, $\Phi^{-1}$ the inverse of the standard normal CDF and $\Phi_\Sigma$ the Gaussian CDF of correlation matrix $\Sigma$. We define the Gaussian copula in the following way:
$$F(X_1, ..., X_d)=C_\Sigma(F_1(X_1), ..., F_d(X_d)):=\Phi_\Sigma(\Phi^{-1}(F_1(X_1)), ..., \Phi^{-1}(F_d(X_d)))$$
NB: In classical network inference, we often use the precision matrix as we study conditional correlations. For the moment, our method only estimates the correlation matrix of the copula and we suppose that it can be expressed as a block matrix.

## Data simulation

When the correlation matrix $\Sigma$ and the marginal laws $F_1, ..., F_d$ are known, one can easily simulate $X_1, ..., X_d$ via `CopulaSim` which uses the generalized inverse method.
```{r, echo=FALSE}
#an intermediate function to generate a block-wise diagonal matrix
diag_block_matrix <- function(blocs, coeff){
  step=c(0,cumsum(blocs))
  d = sum(blocs)
  R = matrix(0,d,d)
  for(i in 1:(length(step)-1)){
    R[((step[i]+1):step[i+1]),((step[i]+1):step[i+1])]=coeff[i]
  }
  diag(R)=1
  return(R)
}

GCopula <- function(R, n){
  d = dim(R)[1]
  A = as.matrix(eigen(R)$vectors%*%diag(sqrt(eigen(R)$values)))
  z = matrix(rnorm(d*n, mean = 0, sd = 1), ncol=n)
  data <- data.frame(t(pnorm(A%*%z)))
  return(data)
}

CopulaSim <- function(n, blocks, coeff, list_qlaws, repetition, random = TRUE){
  
  R = diag_block_matrix(blocks, coeff)
  d = sum(blocks)
  XY = GCopula(R,n)
  
  nb = c()
  for (l in 1:length(repetition)){
    nb = append(nb, rep(l,repetition[l]))
    }
  if (random == TRUE){
    nb = sample(nb)
  }
  
  vars = matrix(0,n,d)
  for (j in 1:d){
    i = nb[j]
    vars[,j] = list_qlaws[[i]](XY[, j])
  }
  return(data.frame(vars))
}
```
For example, let us suppose that we want to simulate 6 variables on 10 observations which joint CDF can be expressed via a Gaussian copula of correlation matrix
$$\begin{pmatrix} 
1  & 0.2 & 0 & 0 & 0 & 0 \\ 
0.2 & 1 & 0 & 0 & 0 & 0\\
0 & 0 & 1& 0.1 & 0 & 0 \\
0 & 0 & 0.1 & 1 & 0 & 0 \\
0 & 0 & 0 & 0 & 1 & 0.5\\
0& 0 & 0 & 0 & 0.5 & 1
\end{pmatrix}$$
 and where two of the variables follow a $\mathcal{E}(1)$ distribution, two of them a $\mathcal{N}(0,1)$ distribution, and the remaining two a $\mathcal{N}(0.76,2)$ distribution, we can run the following code
```{r, results='hide'}
CopulaSim(10, c(2,2,2), c(0.2,0.1,0.5), list(function(p){qexp(p=p, rate=1)}, function(p){qnorm(p=p, mean=0, sd=1)}, function(p){qnorm(p=p, mean=0.76, sd=2)}), c(5,4,4), random = TRUE)
```
which provides us with the following results:
```{r, echo=FALSE}
data <- CopulaSim(10, c(2,2,2), c(0.2,0.1,0.5), list(function(p){qexp(p=p, rate=1)}, function(p){qnorm(p=p, mean=0, sd=1)}, function(p){qnorm(p=p, mean=0.76, sd=2)}), c(5,4,4), random = TRUE)

colnames(data)<-c("X1", "X2", "X3", "X4", "X5", "X6")

knitr::kable(data,align="c")
```
`CopulaSim` uses the generalized inverse method, that is:

* Step 1: Simulation of a vector $(U_1, ..., U_d)$ of probabilities for Gaussian data linked by a correlation matrix $\Sigma$.
* Step 2: For each $U_j$, $X_j=F_j^{\leftarrow}(U_j)$ where $F_j^{\leftarrow}$ denotes the quantile function of $X_j$

The package also enables the user to simulate the vector of probabilities via the `GCopula` function that is actually used in `CopulaSim`.

For example, if we want to simulate the probabilities for 3 Gaussian vectors of length 10 that are linked by the correlation matrix
$$\begin{pmatrix} 
1  & 0.2 & 0.4 \\ 
0.2 & 1 &0.7\\
0.4&0.7&1
\end{pmatrix}$$
we simply have to run the following code:
```{r, results='hide'}
R <- matrix(c(1,0.2,0.4,0.2,1,0.7,0.4,0.7,1),3,3)
n<- 10
GCopula(R,n)
```
This function returns three gaussian vectors linked by the correlation matrix $\Sigma$ such as in the table below:
```{r, echo=F}
R <- matrix(c(1,0.2,0.4,0.2,1,0.7,0.4,0.7,1),3,3)
n<- 10
data1 <-GCopula(R,n)
colnames(data1)<-c("U1", "U2","U3")
knitr::kable(data1, align='c')
```
The package also provides the user with the function `diag_block_matrix` which simulates a block-wise correlation matrix in which the size of blocks and the coefficients have to be specified as arguments. It is also used by `CopulaSim`. For example, the following code
```{r, results="hide"}
diag_block_matrix(c(2,5,3), c(0.2,0.75,0.5))
```
returns the following matrix
$$\begin{pmatrix} 
1  & 0.2 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 \\ 
0.2 & 1 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 \\
0  & 0 & 1 & 0.75 & 0.75 & 0.75 & 0.75 & 0 & 0 & 0 \\ 
0  & 0 & 0.75 & 1 & 0.75 & 0.75 & 0.75 & 0 & 0 & 0 \\ 
0  & 0 & 0.75 & 0.75 & 1 & 0.75 & 0.75 & 0 & 0 & 0 \\ 
0  & 0 & 0.75 & 0.75 & 0.75 & 1 & 0.75 & 0 & 0 & 0 \\ 
0  & 0 & 0.75 & 0.75 & 0.75 & 0.75 & 1 & 0 & 0 & 0 \\ 
0  & 0 & 0 & 0 & 0 & 0 & 0 & 1 & 0.5 & 0.5 \\ 
0  & 0 & 0 & 0 & 0 & 0 & 0 & 0.5 & 1 & 0.5 \\ 
0  & 0 & 0 & 0 & 0 & 0 & 0 & 0.5 & 0.5 & 1 \\ 
\end{pmatrix}$$

# Correlation matrix estimation

Besides simulating the data, the package also enables the user to estimate the correlation matrix of the copula via the `rho_estim` function.

```{r, echo=FALSE}
# First, we are going to create several auxiliary functions

#This function estimates the CDF values for each variable
fdr_d <- function(X, Type){
  F <- array(0,dim=c(dim(X)[1],dim(X)[2],2))
  F[,,2] <- sapply(X,rank,ties.method="max")/(dim(X)[1]+1)
  F_s <- rbind(0,apply(F[,,2],2,sort))
  for (i in 1:dim(X)[2]){
    if (Type[i] == "D"){
      for(j in 1:dim(X)[1]){
        F[j,i,1]=F_s[min(which(F_s[,i]==F[j,i,2]))-1,i]
      }
    }
  }
  return(F)
}


### Copule gaussienne ###

c_R_2D <- function(x1, x2, rho) + return(exp(-0.5*((rho**2)*(qnorm(x1,0,1)**2+qnorm(x2,0,1)**2)-2*rho*qnorm(x1,0,1)*qnorm(x2,0,1))/(1-rho**2))/sqrt(1-(rho**2)))

C_R_2D<- function(u, v, R){
  return(mvtnorm::pmvnorm(upper=c(qnorm(u1,0,1), qnorm(u2,0,1)),mean=c(0,0),lower=c(qnorm(l1,0,1), qnorm(l2,0,1)),corr = R, sigma=NULL, algorithm = mvtnorm::GenzBretz(), keepAttr=FALSE))
}

# Log-likelihood

L_n_CC <- function(theta, F1, F2){
  delta = 10**-9
  mysummands <- c_R_2D(F1, F2, theta)
  L <- sum(log(mapply(max,mysummands,MoreArgs=list(delta))))
  return(-L)
}

L_n_DD <- function(theta, F1m, F1p, F2m, F2p){
  R = matrix(c(1, theta, theta, 1), 2, 2)
  delta = 10**-9
  mysummands <- mapply(C_R_2D,F1p, F2p, F1m, F2m, MoreArgs=list(R))
  L <- sum(log(mapply(max,mysummands,MoreArgs=list(delta))))
  return(-L)
}

L_n_CD <- function(theta, F1, F2m, F2p){
  delta=10**-9
  mysummands <- pnorm(F2p,mean=theta*qnorm(F1),sd=sqrt(1-theta**2)) - pnorm(F2m,mean=theta*qnorm(F1),sd=sqrt(1-theta**2))
  L <-sum(log(mapply(max,mysummands,MoreArgs=list(delta))))
  return(-L)
}

#Estimer la copule

rho_estim <- function(data, Type){
  F = fdr_d(data, Type)
  M_rho = diag(length(Type))
  for (i in 1:(length(Type)-1)){
    for (j in (i+1):length(Type)){
      if (Type[i] == "C" & Type[j] == "C"){
        rho_ij <- optimize(L_n_CC, c(-1,1), F1 = F[,i,2], F2 = F[,j,2], maximum = FALSE)$minimum
      }
      if(Type[i] == "C" & Type[j] == "D"){
        rho_ij <- optimize(L_n_CD, c(-1,1), F1 = F[,i,2], F2m = F[,j,1], F2p = F[,j,2],maximum = FALSE)$minimum
      }
      if(Type[j] == "C" & Type[i] == "D"){
        rho_ij <- optimize(L_n_CD, c(-1,1), F1 = F[,j,2], F2m = F[,i,1], F2p = F[,i,2],maximum = FALSE)$minimum
      }
      if(Type[j] == "D" & Type[i] == "D"){
        rho_ij <- optimize(L_n_DD, c(-1,1), F1m = F[,i,1], F1p = F[,i,2], F2m = F[,j,1], F2p = F[,j,2],maximum = FALSE)$minimum
      }
      M_rho[i,j] = rho_ij
      M_rho[j,i] = rho_ij
    }
  }
  return(M_rho)
}

```

The function takes as arguments a data frame containing $(X_1, ...., X_d)$ as well as the shape (vector or matrix) depending on the dimension of the data and returns a correlation matrix or a correlation coefficient.

For example, the code below takes as an argument the data from above.
```{r, results='hide'}
rho_estim(data,rep("C",6))
```
It returns the following estimated correlation matrix:
```{r, echo=FALSE}
rho_estim(data,rep("C",6))
```

To do so, it maximizes the pairwise likelihood, that is (@mazo):

$$L_n(\Sigma)=\dfrac{1}{n}\sum_{i=1}^n\sum_{j=1}^d\sum_{j'=j+1}^d\log f_{jj'}(X_{ij}, X_{ij'};\widehat{F}_{j},\widehat{F}_{j'},\Sigma)$$
where the matrix $\Sigma$ denotes the correlation matrix of the copula described above, $X_j$ and $X_j'$ a pair of variables and $\hat{F}_j$ and $\hat{F}_{j'}$ the corresponding empirical distribution functions of said variables. Moreover, $f_{jj'}$ denotes the pairwise density of the pair $X_j$, $X_{j'}$ which expression differs depending on the nature of the variables. When both variables are continuous, it takes the following expression:
$$f(x_j,x_{j'},\widehat{F}_j,\widehat{F}_{j'},\rho)=c_\rho(\widehat{F}_j(x_j), \widehat{F}_{j'}(x_j))f_j(x_j)f_{j'}(x_{j'})$$
where 
$$c_{\rho}(u,v)=\dfrac{1}{\sqrt{1-\rho^2}}\exp\left(\dfrac{2\rho\Phi^{-1}(u)\Phi^{-1}(v)-\rho^2(\Phi^{-1}(u)^2+\Phi^{-1}(v)^2)}{2(1-\rho^2)}\right)$$
denotes the density of the Gaussian copula.
When both variables are discrete, it takes the following expression:
$$\mathbb{P}(X_j=x_j, X_{j'}=x_{j'})=C_\rho(\widehat{F}_j(x_j),\widehat{F}_{j'}(x_{j'}))+ C_\rho(\widehat{F}_j(x_j-\epsilon_j)\widehat{F}_{j'}(x_{j'}-\epsilon_{j'}))- C_\rho(\widehat{F}_j(x_j-\epsilon_j),\widehat{F}_{j'}(x_{j'}))-C_\rho(\widehat{F}_j(x_j),\widehat{F}_{j'}(x_{j'}-\epsilon_{j'}))$$
If $X_j$ is continuous and $X_{j'}$ is discrete, it takes the expression below:
$$f(x_j, x_{j'})=f_1(x_1)\int_{\widehat{F}_{j'}(x_{j'}-\epsilon_{j'})}^{\widehat{F}_{j'}(x_{j'})}c_\rho(\widehat{F}_j(x_j), v')\lambda(dv')$$
```{r, echo=FALSE}
#thresholding functions
matrix_cor_01 <- function(M_est, TS){
  M_ = M_est
  M_[which(M_ <= TS)] = 0
  M_[which(M_ != 0)] = 1
  return(M_)
}

matrix_cor_w <- function(M_est, TS){
  M_ = M_est
  M_[which(M_ <= TS)] = 0
  return(M_)
}
cor_network_graph <- function(data, Type, TS, Weighted = FALSE, vertex_col){
  
  M = rho_estim(data, Type)
  if (Weighted == FALSE){
    network_ref <- igraph::graph_from_adjacency_matrix(matrix_cor_01(M, TS), mode="undirected", diag=F)
  }
  else{network_ref <- igraph::graph_from_adjacency_matrix(matrix_cor_w(M, TS), mode="undirected", weighted = TRUE, diag=F)}
  
  par(bg="white", mar=c(1,1,1,1))
  plot(network_ref,
       vertex.size=12,
       vertex.label = names(data),
       vertex.color=vertex_col,
       vertex.label.cex=0.8,
       vertex.label.color="black",
       vertex.frame.color="black",
       edge.color = "black")
  
  text(1,-1, stringr::str_glue("Correlation network (threshold = ",TS,")") ,col="black", cex=0.9)
}
```

Finally, the package enables the user to plot the correlation network from a dataframe containing the initial variables via the function `cor_network_graph` in which you have to specify your correlation threshold, whether the length of the edges is proportional to the weight of the variables, and the color of the vertices. For example, if we take the dataset from above, the function below returns its correlation graph thresholded at 0.3.

```{r}
cor_network_graph(data, rep("C",6), 0.3, TRUE, "orange")
```

